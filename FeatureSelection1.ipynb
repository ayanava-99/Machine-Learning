{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeatureSelection1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOeWl3DMqKepQViFUnx+ivI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Machine-Learning/blob/master/FeatureSelection1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOcesl303r56",
        "colab_type": "text"
      },
      "source": [
        "# **Remove features with low variance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDFQycru2-qn",
        "colab_type": "text"
      },
      "source": [
        "As an example, suppose that we have a dataset with boolean features, and we want to remove all features that are either one or zero (on or off) in more than 80% of the samples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POAg-2gY24St",
        "colab_type": "text"
      },
      "source": [
        "Create a datasest with 3 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcYMkGMb2skT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "X = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnwIBmvd28Os",
        "colab_type": "text"
      },
      "source": [
        "Remove all variables where the variance does not meet the threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCO728Dl3Tg0",
        "colab_type": "text"
      },
      "source": [
        "As expected, VarianceThreshold has removed the first column, which has a probability  > .8 of containing a zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fva4hqMO23Zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
        "sel.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJIHYCf33xcY",
        "colab_type": "text"
      },
      "source": [
        "# **Univariate feature selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkcCUMF437fG",
        "colab_type": "text"
      },
      "source": [
        "Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8JrQGnX_gPd",
        "colab_type": "text"
      },
      "source": [
        ">SelectKBest removes all but the k highest scoring features<br>\n",
        "<br>\n",
        "SelectPercentile removes all but a user-specified highest scoring percentage of features<br>\n",
        "<br>\n",
        "using common univariate statistical tests for each feature: false positive rate SelectFpr, false discovery rate SelectFdr, or family wise error SelectFwe.<br>\n",
        "<br>\n",
        "GenericUnivariateSelect allows to perform univariate feature selection with a configurable strategy. This allows to select the best univariate selection strategy with hyper-parameter search estimator.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8B00pdK73A9",
        "colab_type": "text"
      },
      "source": [
        "**Example 1:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP_5KUtl4JAQ",
        "colab_type": "text"
      },
      "source": [
        "SelectKBest removes all but the *k* highest scoring features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwgyLw104RmF",
        "colab_type": "text"
      },
      "source": [
        "Get the Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apd5gGI038ut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFoLUqYr4UM0",
        "colab_type": "text"
      },
      "source": [
        "These objects take as input a scoring function that returns univariate scores and p-values (or only scores for SelectKBest and SelectPercentile)<br><br>\n",
        "Select the two highest scoring features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTqmfKV64QI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
        "X_new.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rZc7Saf42Xk",
        "colab_type": "text"
      },
      "source": [
        "**Example 2: Check model performance after variable selection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgWBWHot5Ggn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_selection import SelectKBest, f_classif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldQX2LpN5S35",
        "colab_type": "text"
      },
      "source": [
        "**Get data and add noise to the dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBVBraRJ6pb6",
        "colab_type": "text"
      },
      "source": [
        "This Iris dataset has 24 features and 150 rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79mQ2T0v5Le-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the Iris dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Some noisy data not correlated\n",
        "E = np.random.RandomState(42).uniform(0, 0.1, size=(X.shape[0], 20))\n",
        "\n",
        "# Add the noisy data to the informative features\n",
        "X = np.hstack((X, E))\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBnIyEZS5ciu",
        "colab_type": "text"
      },
      "source": [
        "**Do the train-test split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e__nGiTs5ctJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split dataset to select feature and evaluate the classifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, stratify=y, random_state=0\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FP8xze960k3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_indices = np.arange(X.shape[-1])\n",
        "\n",
        "# #############################################################################\n",
        "# Univariate feature selection with F-test for feature scoring\n",
        "# We use the default selection function to select the four\n",
        "# most significant features\n",
        "# #############################################################################\n",
        "\n",
        "selector = SelectKBest(f_classif, k=4)\n",
        "selector.fit(X_train, y_train)\n",
        "scores = -np.log10(selector.pvalues_)\n",
        "scores /= scores.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unYrXy1w8vl0",
        "colab_type": "text"
      },
      "source": [
        "**Create an SVM model and train it on all the features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUqPYLrY8beH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compare to the weights of an SVM\n",
        "clf = make_pipeline(MinMaxScaler(), LinearSVC())\n",
        "clf.fit(X_train, y_train)\n",
        "print('Classification accuracy without selecting features: {:.3f}'\n",
        "      .format(clf.score(X_test, y_test)))\n",
        "\n",
        "svm_weights = np.abs(clf[-1].coef_).sum(axis=0)\n",
        "svm_weights /= svm_weights.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIBc_vio813K",
        "colab_type": "text"
      },
      "source": [
        "**Create an SVM and train it with only the selected features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1v6GqYa8raL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf_selected = make_pipeline(\n",
        "        SelectKBest(f_classif, k=4), MinMaxScaler(), LinearSVC()\n",
        ")\n",
        "clf_selected.fit(X_train, y_train)\n",
        "print('Classification accuracy after univariate feature selection: {:.3f}'\n",
        "      .format(clf_selected.score(X_test, y_test)))\n",
        "\n",
        "svm_weights_selected = np.abs(clf_selected[-1].coef_).sum(axis=0)\n",
        "svm_weights_selected /= svm_weights_selected.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKAGpuqY42j0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(1)\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.clf()\n",
        "\n",
        "plt.bar(X_indices - .45, scores, width=.2,\n",
        "        label=r'Univariate score ($-Log(p_{value})$)')\n",
        "\n",
        "plt.bar(X_indices - .25, svm_weights, width=.2, label='SVM weight')\n",
        "\n",
        "plt.bar(X_indices[selector.get_support()] - .05, svm_weights_selected,\n",
        "        width=.2, label='SVM weights after selection')\n",
        "\n",
        "plt.title(\"Comparing feature selection\")\n",
        "plt.xlabel('Feature number')\n",
        "plt.yticks(())\n",
        "plt.axis('tight')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5_JuVR5A5AS",
        "colab_type": "text"
      },
      "source": [
        "# **Recursive feature elimination**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxoH5EigB2m1",
        "colab_type": "text"
      },
      "source": [
        "Select features by recursively considering smaller and smaller sets of features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h40xDwCHEFes",
        "colab_type": "text"
      },
      "source": [
        "A recursive feature elimination example showing the relevance of pixels in a digit classification task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_EeaIamB7f9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.feature_selection import RFE\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH9bq_cBCVs5",
        "colab_type": "text"
      },
      "source": [
        "**Load the digits dataset (classification)**.<br>\n",
        "\n",
        "Each datapoint is a 8x8 image of a digit.<br>\n",
        ">Classes: 10<br>\n",
        ">Samples per class: ~180<br>\n",
        ">Samples total: 1797<br>\n",
        ">Dimensionality: 64<br>\n",
        ">Features: integers 0-16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j-ZCYFMB_vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "print(digits.data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x73tlGFjCzlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "choice = 9\n",
        "plt.gray() \n",
        "plt.matshow(digits.images[choice]) \n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtqs9FgQCLOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X[choice]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xisTpJlaCJPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y[choice]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jb8botiCGcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the Recursive Feature Elimination (RFE) object and rank each pixel\n",
        "svc = SVC(kernel=\"linear\", C=1)\n",
        "rfe = RFE(estimator=svc, n_features_to_select=1, step=1)\n",
        "rfe.fit(X, y)\n",
        "ranking = rfe.ranking_.reshape(digits.images[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0lukojWA-pG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot pixel ranking\n",
        "plt.matshow(ranking, cmap=plt.cm.Blues)\n",
        "plt.colorbar()\n",
        "plt.title(\"Ranking of pixels with RFE\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zlr1NriEZlV",
        "colab_type": "text"
      },
      "source": [
        "**RFE Example  2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOHbdbSFEpNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.datasets import make_classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NQRbGkEEw_X",
        "colab_type": "text"
      },
      "source": [
        "**Create the data with 3 informative features and 25 features total**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCq1iS_cE4IE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a classification task using 3 informative features\n",
        "X, y = make_classification(n_samples=1000, n_features=25, n_informative=3,\n",
        "                           n_redundant=2, n_repeated=0, n_classes=8,\n",
        "                           n_clusters_per_class=1, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUXLTTroE-0i",
        "colab_type": "text"
      },
      "source": [
        "**Create the RFE object**<br>\n",
        "Using a cross-validated score, recursively eliminate the less important features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLZkiT8FE9YO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the RFE object and compute a cross-validated score.\n",
        "svc = SVC(kernel=\"linear\")\n",
        "# The \"accuracy\" scoring is proportional to the number of correct\n",
        "# classifications\n",
        "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2),\n",
        "              scoring='accuracy')\n",
        "rfecv.fit(X, y)\n",
        "\n",
        "print(\"Optimal number of features : %d\" % rfecv.n_features_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S8oCqCRFUr5",
        "colab_type": "text"
      },
      "source": [
        "**Plot the score vs number of features selected**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxiZTZoyEdaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot number of features VS. cross-validation scores\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b59LdV1cG5gV",
        "colab_type": "text"
      },
      "source": [
        "# **SelectFromModel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_ENV5cQKoon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kXicbxPKttO",
        "colab_type": "text"
      },
      "source": [
        "**Create data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlZCfGnjG5tG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = [[ 0.87, -1.34,  0.31, -0.99],\n",
        "     [-2.79, -0.02, -0.85, 0.5 ],\n",
        "     [-1.34, -0.48, -2.55, 2.01 ],\n",
        "     [ 1.92,  1.48,  0.65, 0.95 ]]\n",
        "y = [0, 1, 0, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82Tpdh8ZKs2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selector = SelectFromModel(estimator=LogisticRegression()).fit(X, y)\n",
        "print(\"selector estimator coef: \", selector.estimator_.coef_)\n",
        "print(\"selector threshold: \",selector.threshold_)\n",
        "print(\"selector get support: \",selector.get_support())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUGMAONJLJJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selector.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-qsEES2LtAj",
        "colab_type": "text"
      },
      "source": [
        "# **Tree-based feature selection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVu78eMJMi5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.feature_selection import SelectFromModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Di_PyAWMk-w",
        "colab_type": "text"
      },
      "source": [
        "Load the Iris datset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDeNCmfrMoz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = load_iris(return_X_y=True)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_HYHguBPRjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAH4wz2KPfk8",
        "colab_type": "text"
      },
      "source": [
        "Use the trees classifier to determine the important features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRBuzgCKLxjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = ExtraTreesClassifier(n_estimators=50)\n",
        "clf = clf.fit(X, y)\n",
        "clf.feature_importances_      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMU9_TolPpPC",
        "colab_type": "text"
      },
      "source": [
        "Create a new dataset that uses only the most important features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFqjI_rpMr7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SelectFromModel(clf, prefit=True)\n",
        "X_new = model.transform(X)\n",
        "X_new.shape "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxqPtKsbPUIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_new[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NpXom4wP5vM",
        "colab_type": "text"
      },
      "source": [
        "Tree based example 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3__TOkj2QAp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import ExtraTreesClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiPefc7oQCR5",
        "colab_type": "text"
      },
      "source": [
        "Create synthetic data<br>\n",
        ">10 features, 3 of them informative\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W54-7BlsQJ0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a classification task using 3 informative features\n",
        "X, y = make_classification(n_samples=1000,\n",
        "                           n_features=10,\n",
        "                           n_informative=3,\n",
        "                           n_redundant=0,\n",
        "                           n_repeated=0,\n",
        "                           n_classes=2,\n",
        "                           random_state=0,\n",
        "                           shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc0iQoqGQPAe",
        "colab_type": "text"
      },
      "source": [
        "**Build a forest** and compute the impurity-based feature importances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2IfvxG6QNkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forest = ExtraTreesClassifier(n_estimators=250,\n",
        "                              random_state=0)\n",
        "forest.fit(X, y)\n",
        "importances = forest.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsP3CvUtQfCj",
        "colab_type": "text"
      },
      "source": [
        "**Print the feature ranking**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doxKFoNmQbsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Feature ranking:\")\n",
        "for f in range(X.shape[1]):\n",
        "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZkm-Zp-QrBs",
        "colab_type": "text"
      },
      "source": [
        "**Plot the impurity-based feature importances of the forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhHSDFh_P7Z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(X.shape[1]), importances[indices],\n",
        "        color=\"r\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(X.shape[1]), indices)\n",
        "plt.xlim([-1, X.shape[1]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}